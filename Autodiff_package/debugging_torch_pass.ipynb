{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruker\\anaconda3\\envs\\SAXSTT\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from forward_backward_AD import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time, timeit\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruker\\anaconda3\\envs\\SAXSTT\\lib\\site-packages\\scipy\\io\\matlab\\mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "workspace = scipy.io.loadmat(r'../Data Sets/Debug Data/validation_python_workspace.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'opt_inputs', 'p', 's', 'projection', 'E', 'numOfCoeffs', 'skip_optimization', 'None', 'return_synth_proj', 'return_Ereg', 'find_coefficients', 'find_orientation', 'find_grad', 'phi_det', 'theta_det', 'l', 'm', 'nx', 'ny', 'nz', 'numOfsegments', 'numOfvoxels', 'mask3D', 'numOfpixels', 'numOfordersopt', 'theta_struct', 'phi_struct', 'a', 'ii', 'grad_a', 'grad_theta_struct', 'grad_phi_struct', 'zeros_struct', 'Ylm_coef', 'a_temp', 'a_temp1', 'a_temp2', 'ones_struct', 'unit_q_beamline', 'N', 'x', 'y', 'z', 'X', 'Y', 'Z', 'current_projection', '__function_workspace__'])\n"
     ]
    }
   ],
   "source": [
    "print(workspace.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_struct_it = workspace['theta_struct']\n",
    "phi_struct_it = workspace['phi_struct']\n",
    "a_temp_it =    workspace['a_temp']\n",
    "ny = workspace['ny']\n",
    "nx = workspace['nx']\n",
    "nz = workspace['nz']\n",
    "numOfsegments = workspace['numOfsegments']\n",
    "current_projection = workspace['projection'][0,0]#[2]\n",
    "p = workspace['p']\n",
    "X = workspace['X']\n",
    "Y = workspace['Y']\n",
    "Z = workspace['Z']\n",
    "numOfpixels = workspace['numOfpixels']\n",
    "unit_q_beamline = workspace['unit_q_beamline']\n",
    "Ylm_coef = workspace['Ylm_coef']\n",
    "find_coefficients = workspace['find_coefficients']\n",
    "find_orientation = workspace['find_orientation']\n",
    "numOfCoeffs = workspace['numOfCoeffs']\n",
    "numOfvoxels = workspace['numOfvoxels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "64\n",
      "<class 'int'>\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]], dtype=torch.float64)\n",
      "torch.Size([4, 4, 8])\n",
      "(4, 4, 8)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "#print(current_projection[0,0][2].shape)\n",
    "# Testing shit\n",
    "\n",
    "print(type(numOfvoxels))\n",
    "\n",
    "yo = int(np.squeeze(numOfvoxels))\n",
    "\n",
    "print(yo)\n",
    "\n",
    "print(type(yo))\n",
    "\n",
    "new_tens = torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], dtype=torch.float64).reshape(4,4)\n",
    "print(new_tens)\n",
    "\n",
    "\n",
    "A = torch.rand((3,3,64))\n",
    "B = torch.rand((3,8))\n",
    "#C = torch.matmul(A[0], B) # Have to figure out how this works. \n",
    "\n",
    "projection_data = torch.tensor(\n",
    "        current_projection[\"data\"])\n",
    "\n",
    "print(projection_data.shape)\n",
    "\n",
    "print(current_projection[\"data\"].shape)\n",
    "print(current_projection[\"Rot_exp\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done debugging. Error is at least correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Before a_temp_it shape: 343\n",
      "DEBUG:root:After a_temp_it shape: torch.Size([1, 1, 343])\n",
      "DEBUG:root:Rot_str shape: torch.Size([3, 3, 343])\n",
      "DEBUG:root:unit_q_object shape: torch.Size([3, 8])\n",
      "DEBUG:root:A shape: torch.Size([3, 3, 343])\n",
      "DEBUG:root:B shape: torch.Size([3, 8])\n",
      "DEBUG:root:cos_theta_sh_cut shape: torch.Size([8, 343])\n",
      "DEBUG:root:Ylm_coef: tensor([0.2821], dtype=torch.float64)\n",
      "DEBUG:root:block_cos_theta_powers shape: torch.Size([1, 8, 343])\n",
      "DEBUG:root:A shape: torch.Size([1])\n",
      "DEBUG:root:B shape: torch.Size([1, 8, 343])\n",
      "DEBUG:root:A dims: 2\n",
      "DEBUG:root:B dims: 3\n",
      "DEBUG:root:Ylm shape: torch.Size([1, 8, 343])\n",
      "DEBUG:root:a_temp shape: torch.Size([1, 1, 343])\n",
      "DEBUG:root:A shape: torch.Size([1, 1, 343])\n",
      "DEBUG:root:B shape: torch.Size([1, 8, 343])\n",
      "DEBUG:root:sumlm_alm_Ylm shape: torch.Size([1, 8, 343])\n",
      "DEBUG:root:data_synt_vol shape: torch.Size([7, 7, 7, 8])\n",
      "DEBUG:root:Data type, shape: torch.float64, torch.Size([7, 7, 8])\n",
      "DEBUG:root:xout shape: (7,)\n",
      "DEBUG:root:yout shape: (7,)\n",
      "DEBUG:root:\n",
      "xout: [-3. -2. -1.  0.  1.  2.  3.]\n",
      "yout: [-3. -2. -1.  0.  1.  2.  3.]\n",
      "DEBUG:root:proj_out_all shape: torch.Size([7, 7, 8])\n",
      "DEBUG:root:tomo_obj_all shape: torch.Size([7, 7, 7, 8])\n",
      "DEBUG:root:nRows: 7 nCols: 7 nPages: 8\n",
      "DEBUG:root:proj_out_all before conv:\n",
      "tensor([[[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09, 5.6671e-09,\n",
      "          5.6671e-09, 5.6671e-09, 5.6671e-09],\n",
      "         [5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09, 5.6551e-09,\n",
      "          5.6551e-09, 5.6551e-09, 5.6551e-09],\n",
      "         [5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09, 5.6550e-09,\n",
      "          5.6550e-09, 5.6550e-09, 5.6550e-09],\n",
      "         [2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09, 2.9655e-09,\n",
      "          2.9655e-09, 2.9655e-09, 2.9655e-09]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00]]], grad_fn=<PermuteBackward0>)\n",
      "DEBUG:root:Elems included: 258\n",
      "DEBUG:root:filter_2D: tensor([[0.0278, 0.1111, 0.0278],\n",
      "        [0.1111, 0.4444, 0.1111],\n",
      "        [0.0278, 0.1111, 0.0278]])\n",
      "DEBUG:root:filter_2D shape: torch.Size([8, 1, 3, 3])\n",
      "DEBUG:root:full filter 2D: tensor([[[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[0.0278, 0.1111, 0.0278],\n",
      "          [0.1111, 0.4444, 0.1111],\n",
      "          [0.0278, 0.1111, 0.0278]]]])\n",
      "DEBUG:root:proj_out_all before conv shape: torch.Size([7, 7, 8])\n",
      "DEBUG:root:proj_out_all ready conv: tensor([[2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [2.9655e-09, 5.6550e-09, 5.6550e-09, 5.6671e-09, 5.6551e-09, 5.6550e-09,\n",
      "         2.9655e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<SliceBackward0>)\n",
      "DEBUG:root:proj_out_all after conv before permutation: tensor([[[[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]],\n",
      "\n",
      "         [[2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.9195e-09, 5.2068e-09, 5.6571e-09, 5.6631e-09, 5.6571e-09,\n",
      "           5.2068e-09, 2.9195e-09],\n",
      "          [2.4329e-09, 4.3390e-09, 4.7142e-09, 4.7193e-09, 4.7142e-09,\n",
      "           4.3390e-09, 2.4329e-09],\n",
      "          [4.8658e-10, 8.6780e-10, 9.4284e-10, 9.4385e-10, 9.4284e-10,\n",
      "           8.6780e-10, 4.8658e-10]]]], grad_fn=<ConvolutionBackward1>)\n",
      "DEBUG:root:proj_out_all after conv shape: torch.Size([7, 7, 8])\n",
      "DEBUG:root:data shape: torch.Size([7, 7, 8])\n",
      "DEBUG:root:Ad_grad_coeff: tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.0004e-04, -1.2558e-04, -1.2832e-04,\n",
      "          -1.2866e-04, -1.2907e-04, -1.3733e-04,  0.0000e+00, -1.1180e-04,\n",
      "          -1.4033e-04, -1.4340e-04, -1.4378e-04, -1.4424e-04, -1.5347e-04,\n",
      "           0.0000e+00, -1.1277e-04, -1.4156e-04, -1.4465e-04, -1.4504e-04,\n",
      "          -1.4549e-04, -1.5481e-04,  0.0000e+00, -1.1295e-04, -1.4178e-04,\n",
      "          -1.4488e-04, -1.4526e-04, -1.4572e-04, -1.5505e-04,  0.0000e+00,\n",
      "          -1.1387e-04, -1.4294e-04, -1.4606e-04, -1.4645e-04, -1.4691e-04,\n",
      "          -1.5632e-04,  0.0000e+00, -1.0805e-04, -1.3563e-04, -1.3860e-04,\n",
      "          -1.3897e-04, -1.3941e-04, -1.4833e-04,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.0389e-04, -1.3041e-04, -1.3325e-04, -1.3361e-04,\n",
      "          -1.3403e-04, -1.4261e-04,  0.0000e+00, -1.1211e-04, -1.4072e-04,\n",
      "          -1.4380e-04, -1.4418e-04, -1.4464e-04, -1.5390e-04,  0.0000e+00,\n",
      "          -1.1280e-04, -1.4159e-04, -1.4468e-04, -1.4507e-04, -1.4553e-04,\n",
      "          -1.5484e-04,  0.0000e+00, -1.1299e-04, -1.4183e-04, -1.4492e-04,\n",
      "          -1.4531e-04, -1.4577e-04, -1.5511e-04,  0.0000e+00, -1.1418e-04,\n",
      "          -1.4333e-04, -1.4646e-04, -1.4685e-04, -1.4731e-04, -1.5674e-04,\n",
      "           0.0000e+00, -1.0533e-04, -1.3221e-04, -1.3510e-04, -1.3546e-04,\n",
      "          -1.3589e-04, -1.4459e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -1.0774e-04, -1.3524e-04, -1.3819e-04, -1.3856e-04, -1.3900e-04,\n",
      "          -1.4790e-04,  0.0000e+00, -1.1242e-04, -1.4111e-04, -1.4420e-04,\n",
      "          -1.4458e-04, -1.4504e-04, -1.5432e-04,  0.0000e+00, -1.1282e-04,\n",
      "          -1.4162e-04, -1.4471e-04, -1.4510e-04, -1.4556e-04, -1.5488e-04,\n",
      "           0.0000e+00, -1.1303e-04, -1.4188e-04, -1.4497e-04, -1.4536e-04,\n",
      "          -1.4582e-04, -1.5516e-04,  0.0000e+00, -1.1449e-04, -1.4372e-04,\n",
      "          -1.4685e-04, -1.4725e-04, -1.4771e-04, -1.5717e-04,  0.0000e+00,\n",
      "          -1.0260e-04, -1.2879e-04, -1.3160e-04, -1.3196e-04, -1.3237e-04,\n",
      "          -1.4085e-04,  0.0000e+00, -8.9762e-05, -1.1267e-04, -1.1513e-04,\n",
      "          -1.1544e-04, -1.1581e-04, -1.2322e-04,  0.0000e+00, -1.1096e-04,\n",
      "          -1.3929e-04, -1.4233e-04, -1.4271e-04, -1.4316e-04, -1.5233e-04,\n",
      "           0.0000e+00, -1.1271e-04, -1.4147e-04, -1.4456e-04, -1.4495e-04,\n",
      "          -1.4541e-04, -1.5472e-04,  0.0000e+00, -1.1285e-04, -1.4165e-04,\n",
      "          -1.4474e-04, -1.4513e-04, -1.4559e-04, -1.5491e-04,  0.0000e+00,\n",
      "          -1.1306e-04, -1.4192e-04, -1.4502e-04, -1.4541e-04, -1.4587e-04,\n",
      "          -1.5521e-04,  0.0000e+00, -1.1480e-04, -1.4411e-04, -1.4725e-04,\n",
      "          -1.4765e-04, -1.4811e-04, -1.5760e-04,  0.0000e+00, -9.9876e-05,\n",
      "          -1.2537e-04, -1.2811e-04, -1.2845e-04, -1.2886e-04, -1.3711e-04,\n",
      "           0.0000e+00, -9.3610e-05, -1.1750e-04, -1.2007e-04, -1.2039e-04,\n",
      "          -1.2077e-04, -1.2850e-04,  0.0000e+00, -1.1128e-04, -1.3968e-04,\n",
      "          -1.4273e-04, -1.4311e-04, -1.4356e-04, -1.5276e-04,  0.0000e+00,\n",
      "          -1.1273e-04, -1.4150e-04, -1.4459e-04, -1.4498e-04, -1.4544e-04,\n",
      "          -1.5475e-04,  0.0000e+00, -1.1289e-04, -1.4170e-04, -1.4479e-04,\n",
      "          -1.4518e-04, -1.4564e-04, -1.5496e-04,  0.0000e+00, -1.1335e-04,\n",
      "          -1.4228e-04, -1.4539e-04, -1.4578e-04, -1.4624e-04, -1.5560e-04,\n",
      "           0.0000e+00, -1.1261e-04, -1.4135e-04, -1.4444e-04, -1.4483e-04,\n",
      "          -1.4528e-04, -1.5458e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -9.7457e-05, -1.2233e-04, -1.2500e-04, -1.2534e-04, -1.2574e-04,\n",
      "          -1.3379e-04,  0.0000e+00, -1.1159e-04, -1.4007e-04, -1.4313e-04,\n",
      "          -1.4351e-04, -1.4397e-04, -1.5318e-04,  0.0000e+00, -1.1276e-04,\n",
      "          -1.4154e-04, -1.4463e-04, -1.4501e-04, -1.4547e-04, -1.5479e-04,\n",
      "           0.0000e+00, -1.1292e-04, -1.4175e-04, -1.4484e-04, -1.4523e-04,\n",
      "          -1.4569e-04, -1.5502e-04,  0.0000e+00, -1.1366e-04, -1.4267e-04,\n",
      "          -1.4579e-04, -1.4618e-04, -1.4664e-04, -1.5603e-04,  0.0000e+00,\n",
      "          -1.0988e-04, -1.3793e-04, -1.4094e-04, -1.4132e-04, -1.4177e-04,\n",
      "          -1.5084e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0131e-04,\n",
      "          -1.2716e-04, -1.2994e-04, -1.3029e-04, -1.3070e-04, -1.3907e-04,\n",
      "           0.0000e+00, -1.1190e-04, -1.4046e-04, -1.4353e-04, -1.4391e-04,\n",
      "          -1.4437e-04, -1.5361e-04,  0.0000e+00, -1.1278e-04, -1.4157e-04,\n",
      "          -1.4466e-04, -1.4505e-04, -1.4550e-04, -1.5482e-04,  0.0000e+00,\n",
      "          -1.1296e-04, -1.4180e-04, -1.4489e-04, -1.4528e-04, -1.4574e-04,\n",
      "          -1.5507e-04,  0.0000e+00, -1.1397e-04, -1.4306e-04, -1.4619e-04,\n",
      "          -1.4658e-04, -1.4704e-04, -1.5646e-04,  0.0000e+00, -1.0716e-04,\n",
      "          -1.3451e-04, -1.3745e-04, -1.3781e-04, -1.3825e-04, -1.4710e-04,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00]]], dtype=torch.float64)\n",
      "DEBUG:root:error_norm: 0.013586012195733499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.013586012195733499,\n",
       " array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00, -1.00040315e-04, -1.25575553e-04,\n",
       "          -1.28317419e-04, -1.28661917e-04, -1.29068151e-04,\n",
       "          -1.37331472e-04,  0.00000000e+00, -1.11796333e-04,\n",
       "          -1.40332268e-04, -1.43396325e-04, -1.43781305e-04,\n",
       "          -1.44235273e-04, -1.53469602e-04,  0.00000000e+00,\n",
       "          -1.12771933e-04, -1.41556879e-04, -1.44647667e-04,\n",
       "          -1.45036008e-04, -1.45493935e-04, -1.54808837e-04,\n",
       "           0.00000000e+00, -1.12949316e-04, -1.41779532e-04,\n",
       "          -1.44875177e-04, -1.45264130e-04, -1.45722779e-04,\n",
       "          -1.55052332e-04,  0.00000000e+00, -1.13870687e-04,\n",
       "          -1.42936073e-04, -1.46056968e-04, -1.46449092e-04,\n",
       "          -1.46911484e-04, -1.56317136e-04,  0.00000000e+00,\n",
       "          -1.08053213e-04, -1.35633677e-04, -1.38595121e-04,\n",
       "          -1.38967210e-04, -1.39405977e-04, -1.48331081e-04,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.03888016e-04,\n",
       "          -1.30405372e-04, -1.33252692e-04, -1.33610439e-04,\n",
       "          -1.34032297e-04, -1.42613428e-04,  0.00000000e+00,\n",
       "          -1.12107680e-04, -1.40723085e-04, -1.43795673e-04,\n",
       "          -1.44181726e-04, -1.44636957e-04, -1.53897000e-04,\n",
       "           0.00000000e+00, -1.12796870e-04, -1.41588180e-04,\n",
       "          -1.44679651e-04, -1.45068078e-04, -1.45526106e-04,\n",
       "          -1.54843067e-04,  0.00000000e+00, -1.12987714e-04,\n",
       "          -1.41827729e-04, -1.44924426e-04, -1.45313512e-04,\n",
       "          -1.45772317e-04, -1.55105043e-04,  0.00000000e+00,\n",
       "          -1.14181400e-04, -1.43326093e-04, -1.46455504e-04,\n",
       "          -1.46848697e-04, -1.47312351e-04, -1.56743664e-04,\n",
       "           0.00000000e+00, -1.05327592e-04, -1.32212339e-04,\n",
       "          -1.35099078e-04, -1.35461781e-04, -1.35889479e-04,\n",
       "          -1.44589442e-04,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -1.07735717e-04, -1.35235191e-04, -1.38187965e-04,\n",
       "          -1.38558961e-04, -1.38996443e-04, -1.47895383e-04,\n",
       "           0.00000000e+00, -1.12419028e-04, -1.41113902e-04,\n",
       "          -1.44195021e-04, -1.44582147e-04, -1.45038642e-04,\n",
       "          -1.54324399e-04,  0.00000000e+00, -1.12821808e-04,\n",
       "          -1.41619481e-04, -1.44711635e-04, -1.45100148e-04,\n",
       "          -1.45558277e-04, -1.54877297e-04,  0.00000000e+00,\n",
       "          -1.13026112e-04, -1.41875927e-04, -1.44973675e-04,\n",
       "          -1.45362893e-04, -1.45821855e-04, -1.55157754e-04,\n",
       "           0.00000000e+00, -1.14492113e-04, -1.43716114e-04,\n",
       "          -1.46854040e-04, -1.47248302e-04, -1.47713218e-04,\n",
       "          -1.57170192e-04,  0.00000000e+00, -1.02601971e-04,\n",
       "          -1.28791001e-04, -1.31603034e-04, -1.31956352e-04,\n",
       "          -1.32372981e-04, -1.40847803e-04,  0.00000000e+00,\n",
       "          -8.97620218e-05, -1.12673744e-04, -1.15133914e-04,\n",
       "          -1.15443020e-04, -1.15807518e-04, -1.23221881e-04,\n",
       "           0.00000000e+00, -1.10964636e-04, -1.39288286e-04,\n",
       "          -1.42329554e-04, -1.42711669e-04, -1.43162261e-04,\n",
       "          -1.52327901e-04,  0.00000000e+00, -1.12705318e-04,\n",
       "          -1.41473265e-04, -1.44562229e-04, -1.44950341e-04,\n",
       "          -1.45407998e-04, -1.54717399e-04,  0.00000000e+00,\n",
       "          -1.12846745e-04, -1.41650782e-04, -1.44743620e-04,\n",
       "          -1.45132218e-04, -1.45590448e-04, -1.54911527e-04,\n",
       "           0.00000000e+00, -1.13064509e-04, -1.41924125e-04,\n",
       "          -1.45022924e-04, -1.45412275e-04, -1.45871393e-04,\n",
       "          -1.55210465e-04,  0.00000000e+00, -1.14802826e-04,\n",
       "          -1.44106134e-04, -1.47252576e-04, -1.47647907e-04,\n",
       "          -1.48114084e-04, -1.57596719e-04,  0.00000000e+00,\n",
       "          -9.98763500e-05, -1.25369663e-04, -1.28106990e-04,\n",
       "          -1.28450922e-04, -1.28856483e-04, -1.37106164e-04,\n",
       "           0.00000000e+00, -9.36097226e-05, -1.17503564e-04,\n",
       "          -1.20069187e-04, -1.20391542e-04, -1.20771664e-04,\n",
       "          -1.28503836e-04,  0.00000000e+00, -1.11275983e-04,\n",
       "          -1.39679102e-04, -1.42728902e-04, -1.43112089e-04,\n",
       "          -1.43563945e-04, -1.52755299e-04,  0.00000000e+00,\n",
       "          -1.12730255e-04, -1.41504566e-04, -1.44594213e-04,\n",
       "          -1.44982410e-04, -1.45440169e-04, -1.54751629e-04,\n",
       "           0.00000000e+00, -1.12885143e-04, -1.41698980e-04,\n",
       "          -1.44792869e-04, -1.45181599e-04, -1.45639986e-04,\n",
       "          -1.54964238e-04,  0.00000000e+00, -1.13351398e-04,\n",
       "          -1.42284240e-04, -1.45390902e-04, -1.45781239e-04,\n",
       "          -1.46241523e-04, -1.55604288e-04,  0.00000000e+00,\n",
       "          -1.12608494e-04, -1.41351697e-04, -1.44437996e-04,\n",
       "          -1.44825770e-04, -1.45283036e-04, -1.54584415e-04,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00, -9.74574234e-05,\n",
       "          -1.22333383e-04, -1.25004460e-04, -1.25340064e-04,\n",
       "          -1.25735810e-04, -1.33785792e-04,  0.00000000e+00,\n",
       "          -1.11587331e-04, -1.40069919e-04, -1.43128250e-04,\n",
       "          -1.43512510e-04, -1.43965630e-04, -1.53182697e-04,\n",
       "           0.00000000e+00, -1.12755193e-04, -1.41535867e-04,\n",
       "          -1.44626197e-04, -1.45014480e-04, -1.45472340e-04,\n",
       "          -1.54785859e-04,  0.00000000e+00, -1.12923541e-04,\n",
       "          -1.41747177e-04, -1.44842117e-04, -1.45230981e-04,\n",
       "          -1.45689525e-04, -1.55016949e-04,  0.00000000e+00,\n",
       "          -1.13662111e-04, -1.42674260e-04, -1.45789438e-04,\n",
       "          -1.46180844e-04, -1.46642389e-04, -1.56030816e-04,\n",
       "           0.00000000e+00, -1.09882873e-04, -1.37930359e-04,\n",
       "          -1.40941952e-04, -1.41320341e-04, -1.41766538e-04,\n",
       "          -1.50842776e-04,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -1.01305124e-04, -1.27163202e-04, -1.29939733e-04,\n",
       "          -1.30288586e-04, -1.30699956e-04, -1.39067747e-04,\n",
       "           0.00000000e+00, -1.11898678e-04, -1.40460736e-04,\n",
       "          -1.43527598e-04, -1.43912931e-04, -1.44367314e-04,\n",
       "          -1.53610096e-04,  0.00000000e+00, -1.12780130e-04,\n",
       "          -1.41567168e-04, -1.44658181e-04, -1.45046550e-04,\n",
       "          -1.45504511e-04, -1.54820089e-04,  0.00000000e+00,\n",
       "          -1.12961938e-04, -1.41795375e-04, -1.44891366e-04,\n",
       "          -1.45280363e-04, -1.45739063e-04, -1.55069659e-04,\n",
       "           0.00000000e+00, -1.13972824e-04, -1.43064280e-04,\n",
       "          -1.46187974e-04, -1.46580449e-04, -1.47043256e-04,\n",
       "          -1.56457343e-04,  0.00000000e+00, -1.07157252e-04,\n",
       "          -1.34509021e-04, -1.37445908e-04, -1.37814912e-04,\n",
       "          -1.38250040e-04, -1.47101136e-04,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00]]]),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(theta_struct_it, phi_struct_it, a_temp_it, ny, nx, nz, numOfsegments, current_projection, p, X, Y, Z, numOfpixels, unit_q_beamline, Ylm_coef, find_coefficients, find_orientation, numOfCoeffs, numOfvoxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 1]\n",
      " [1 0 2]\n",
      " [1 0 3]]\n",
      "[16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(64).reshape(4,4,4)\n",
    "y = np.arange(64).reshape(4,4,4)\n",
    "\n",
    "lower = np.argwhere( x>10)\n",
    "upper = np.argwhere(x<20)\n",
    "\n",
    "y = np.argwhere( (x>10) & (x<20) & (y>15) & (y<25) )\n",
    "print(y)\n",
    "\n",
    "# Next is out of bounds. Index 5 found when size is 4, index 3 is therefore max. \n",
    "print(x[y[:,0], y[:,1], y[:,2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 8])\n",
      "torch.Size([140, 8])\n",
      "torch.Size([8, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(X)\n",
    "# print('\\n')\n",
    "# print(Y)\n",
    "proj = torch.zeros((7,7,8))\n",
    "Ax =  np.floor(\n",
    "    X - (-1.38545603) + 1\n",
    "    ).astype(int)\n",
    " # Drop +1 due to 0-indexing. AI suggested, but believe I should copy cpp-code\n",
    "Ay = np.floor(Y - (-0.19120833) + 1).astype(int)\n",
    "\n",
    "# print(Ax)\n",
    "# print(Ay)\n",
    "\n",
    "indices = np.argwhere( (Ax>0) & (Ax<7) & (Ay>0) & (Ay<7) )\n",
    "\n",
    "# print(Ax[indices[:,0], indices[:,1], indices[:,2] ])\n",
    "# print(Ay[indices[:,0], indices[:,1], indices[:,2] ])\n",
    "#print(indices[:,:])\n",
    "np.random.seed(0)\n",
    "temp = np.random.random(len(indices[:,0])  )\n",
    "\n",
    "temp = torch.from_numpy(temp).unsqueeze(1)\n",
    "temp = temp.expand(-1,8)\n",
    "tomo = torch.ones((7,7,7,8))\n",
    "\n",
    "proj[Ay[indices[:,0], indices[:,1], indices[:,2] ], Ax[indices[:,0], indices[:,1], indices[:,2] ] ] +=  tomo[indices[:,0], indices[:,1], indices[:,2]] * temp\n",
    "\n",
    "print( (temp* tomo[indices[:,0], indices[:,1], indices[:,2]]).shape ) # Why is the shape 140 times 140??? Some weird broadcasting going on.\n",
    "print(proj[Ay[indices[:,0], indices[:,1], indices[:,2] ], Ax[indices[:,0], indices[:,1], indices[:,2] ] ].shape)\n",
    "print(np.transpose(proj, (2,0,1)).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4]), array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4,\n",
      "       4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5,\n",
      "       5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "       3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
      "       1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "       4, 5, 5, 5, 5, 5, 5, 5]))\n",
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3]), array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4,\n",
      "       4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5,\n",
      "       5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "       3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
      "       1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "       4, 5, 5, 5, 5, 5, 5, 5]))\n",
      "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4]), array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3,\n",
      "       3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
      "       4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "       2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "       3, 4, 4, 4, 4, 4, 4, 4]))\n",
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3]), array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3,\n",
      "       3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
      "       4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "       2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "       3, 4, 4, 4, 4, 4, 4, 4]))\n"
     ]
    }
   ],
   "source": [
    "print( (Ay[indices[:,0], indices[:,1], indices[:,2] ], Ax[indices[:,0], indices[:,1], indices[:,2] ]))\n",
    "print( (Ay[indices[:,0], indices[:,1], indices[:,2] ] -1, Ax[indices[:,0], indices[:,1], indices[:,2] ]) )\n",
    "print( (Ay[indices[:,0], indices[:,1], indices[:,2] ], Ax[indices[:,0], indices[:,1], indices[:,2] ] -1) )\n",
    "print( (Ay[indices[:,0], indices[:,1], indices[:,2] ] -1, Ax[indices[:,0], indices[:,1], indices[:,2] ] -1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out nan values\n",
    "\n",
    "permuted_data = np.load(r\"../permuted_data.npy\") #np.load(r'../Data Sets/Debug Data/permuted_data.npy')\n",
    "proj_out_all = np.load(r\"../proj_out_all.npy\") #np.load(r'../Data Sets/Debug Data/proj_out_all.npy')\n",
    "aux_diff_poisson = np.load(r\"../aux_diff_poisson.npy\") #np.load(r'../Data Sets/Debug Data/aux_diff_poisson.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4, 4)\n",
      "(8, 4, 4)\n",
      "(8, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(permuted_data.shape)\n",
    "print(proj_out_all.shape)\n",
    "print(aux_diff_poisson.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.69836503   0.839173    21.605843   216.13242    102.646805\n",
      "   0.92443      0.6229484    0.5012255 ]\n",
      "[-9.80411e-11 -9.80411e-11 -9.80411e-11 -9.80411e-11 -9.80411e-11\n",
      " -9.80411e-11 -9.80411e-11 -9.80411e-11]\n",
      "[nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "print(permuted_data[:,0,0])\n",
    "print(proj_out_all[:,0,0])\n",
    "print(aux_diff_poisson[:,0,0])\n",
    "# negative projection data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "endgame = torch.zeros((2,2,8), dtype=torch.float64)\n",
    "indices = torch.tensor( [[0,0], [0,0]] )\n",
    "values = torch.ones( (2,8), dtype=torch.float64) \n",
    "#endgame[indices[:,0], indices[:,1], indices[:,2]] += values\n",
    "\n",
    "#endgame[indices[:,0], indices[:,1], indices[:,2]] += values\n",
    "#endgame.scatter_add_(0, indices, values)\n",
    "endgame = torch.index_put(endgame, (indices[:,0], indices[:,1]), values, accumulate=True) #endgame.index_add(0, indices, values, alpha=1)\n",
    "\n",
    "\n",
    "print(endgame) # This is the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SAXSTT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78870d1cbce91eda9675188e6ab147aa27f76fe3d9f15cc56f826954e0ae3aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
